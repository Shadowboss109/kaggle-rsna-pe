experiment:
  cuda: true
  name: mk014
  seed: 88
  save_logs: ../logs/
  save_checkpoints: ../checkpoints/


data: 
  annotations: ../data/train/train_5fold.csv
  data_dir: ../data/train/
  outer_fold: 0
  stack: true
  targets: 
    - pe_present_on_image
    - indeterminate 
    - chronic_pe
    - acute_and_chronic_pe
    - central_pe
    - leftsided_pe
    - rightsided_pe
  dataset:
    name: DICOMDataset
    params:
      window: [100, 700]
      flip: true
      random_hu: 5
      verbose: true


transform:
  resize:
    name: resize_alt
    params:
      imsize: [416, 416]
  augment:
    name: RandAugment
    params:
      n: 3
      m: 12.0
  crop:
    name: crop
    params:
      imsize: [364, 364]
  preprocess:
    name: Preprocessor
    params:
      image_range: [0, 255]
      input_range: [0, 1]
      mean: [0.5, 0.5, 0.5]
      sdev: [0.5, 0.5, 0.5]


model:
  name: Net2D
  params:
    backbone: efficientnet_b3_pruned
    pretrained: true
    num_classes: 7
    dropout: 0.2
    feat_reduce: 512
    multisample_dropout: true
    pool: gem 


loss:
  name: BCEWithLogitsLoss
  params:


optimizer:
  name: RAdam
  params:
    lr: 3.0e-4
    weight_decay: 5.0e-4


scheduler: 
  name: CosineAnnealingLR
  params:
    final_lr: 1.0e-8


train:
  batch_size: 32
  name: Trainer
  params:
    num_epochs: 5
    steps_per_epoch: 2500 # full epoch = 11292 steps @ BS32
    validate_interval: 5
    gradient_accumulation: 1
    amp: true
    verbosity: 100


evaluate: 
  name: Evaluator
  params:
    metrics: [loss, multi_auc]
    valid_metric: loss
    mode: min
    improve_thresh: 1.0e-4
    save_best: true


